{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#MALDI Parser Advanced\n",
    "\n",
    "\n",
    "#Import Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Functions\n",
    "- Finding missed peak(s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding Missed Peak\n",
    "def detect_missed(mzs):\n",
    "    mzs_missing=[]\n",
    "    \n",
    "    for normal_mz in normal_mzs:\n",
    "        for mz in mzs:\n",
    "            if mz<normal_mz+6 and mz>normal_mz-6:   #Searching in this range\n",
    "                break\n",
    "        else:\n",
    "            mzs_missing.append(normal_mz)\n",
    "    return mzs_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding redundant peak(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding Redundant Peak\n",
    "def detect_redundant(mzs):\n",
    "    mzs_adjacents=[]    \n",
    "\n",
    "    for normal_mz in normal_mzs:\n",
    "        d=9.99\n",
    "        m=0\n",
    "        for mz in mzs:\n",
    "            if abs(normal_mz-mz)<d:\n",
    "                d=abs(normal_mz-mz)\n",
    "                m=mz\n",
    "        mzs_adjacents.append(m)\n",
    "   \n",
    "    return mzs_adjacents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layout Display\n",
    "def layout(names):\n",
    "    layout_names=[]\n",
    "    layout_series=[]\n",
    "    for name in names:\n",
    "        patt4=r'[\\D\\d]+_0_'\n",
    "        sample_name=re.findall(patt4, name)[0].replace('_0_', '').replace('-', '_')\n",
    "        \n",
    "        if sample_name.find('standard')!=-1 or sample_name.find('Standard')!=-1:\n",
    "            sample_name=sample_name.replace('standard', '').replace('Standard', '').replace('_', '')       \n",
    "\n",
    "        patt5=r'_0_[\\D\\d]+_1$'\n",
    "        id_name=re.findall(patt5, name)[0].replace('_0_', '').replace('_1', '')\n",
    "\n",
    "        if len(id_name)==2:\n",
    "            id_name=id_name[0]+'0'+id_name[1]\n",
    "\n",
    "         \n",
    "        layout_names.append((id_name, sample_name))\n",
    "\n",
    "    d=96-len(layout_names)\n",
    "\n",
    "    for i in range(d):\n",
    "        layout_names.append(('Z'+str(i),np.nan))\n",
    "\n",
    "    sample_dict=dict(layout_names)\n",
    "    s=pd.Series(sample_dict).sort_index()\n",
    "    df=pd.DataFrame(np.array(s).reshape(8,12),\n",
    "                           columns=[1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "                           index=['A','B','C','D','E','F','G','H'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change certain value into NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make certain cells blank (NaN)\n",
    "def blank():\n",
    "    df['SAA std'][df['level_1']==1]=np.nan\n",
    "    df['SAA std'][df['level_1']==2]=np.nan\n",
    "    df['SAA std'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['SAA avg'][df['level_1']==1]=np.nan\n",
    "    df['SAA avg'][df['level_1']==2]=np.nan\n",
    "    df['SAA avg'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['hep std'][df['level_1']==1]=np.nan\n",
    "    df['hep std'][df['level_1']==2]=np.nan\n",
    "    df['hep std'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['hep avg'][df['level_1']==1]=np.nan\n",
    "    df['hep avg'][df['level_1']==2]=np.nan\n",
    "    df['hep avg'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['SAA/IS_SAA'][df['level_1']==1]=np.nan\n",
    "    df['SAA/IS_SAA'][df['level_1']==2]=np.nan\n",
    "    df['SAA/IS_SAA'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['hep/hhep'][df['level_1']==1]=np.nan\n",
    "    df['hep/hhep'][df['level_1']==2]=np.nan\n",
    "    df['hep/hhep'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['SAA CV'][df['level_1']==1]=np.nan\n",
    "    df['SAA CV'][df['level_1']==2]=np.nan\n",
    "    df['SAA CV'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['hep CV'][df['level_1']==1]=np.nan\n",
    "    df['hep CV'][df['level_1']==2]=np.nan\n",
    "    df['hep CV'][df['level_1']==3]=np.nan\n",
    "\n",
    "    df['name'][df['level_1']==1]=np.nan\n",
    "    df['name'][df['level_1']==2]=np.nan\n",
    "    df['name'][df['level_1']==3]=np.nan\n",
    "        \n",
    "    df['hep avg'][df['Tail']%2==0]=np.nan\n",
    "    df['SAA avg'][df['Tail']%2==0]=np.nan\n",
    "    df['hep std'][df['Tail']%2==0]=np.nan\n",
    "    df['SAA std'][df['Tail']%2==0]=np.nan\n",
    "    df['hep CV'][df['Tail']%2==0]=np.nan\n",
    "    df['SAA CV'][df['Tail']%2==0]=np.nan\n",
    "\n",
    "    df['tag'][df['level_1']==1]=np.nan\n",
    "    df['tag'][df['level_1']==2]=np.nan\n",
    "    df['tag'][df['level_1']==3]=np.nan\n",
    "    df['tag'][df['Tail']%2==0]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Main Program Flow\n",
    "We chose 2 peaks for detection: **2791, 2819** (Hepcidin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D has no label.\n",
      " Volume Serial Number is 9E01-06D9\n",
      "\n",
      " Directory of D:\\ChuanDocuments\\GitHub\\Research\\Project_20160228\n",
      "\n",
      "02/28/2016  11:03 AM    <DIR>          .\n",
      "02/28/2016  11:03 AM    <DIR>          ..\n",
      "02/28/2016  10:07 AM    <DIR>          .ipynb_checkpoints\n",
      "02/27/2016  06:43 PM            82,742 02272016_hepcidin target1_LP.xlsx\n",
      "02/28/2016  11:03 AM            18,430 MALDIParserAdvanced.ipynb\n",
      "               2 File(s)        101,172 bytes\n",
      "               3 Dir(s)  124,203,528,192 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source file: 02272016_hepcidin target1_LP.xlsx loaded!\n",
      "Data Extracted!\n"
     ]
    }
   ],
   "source": [
    "#////////////////MAIN///////////////////////////////////////////////\n",
    "#Ignoring Warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Default Peaks\n",
    "normal_mzs=[2791, 2819]\n",
    "normal_rows=len(normal_mzs)\n",
    "\n",
    "#Import File\n",
    "filename='02272016_hepcidin target1_LP.xlsx'\n",
    "book=xlrd.open_workbook(filename)\n",
    "print('Source file: '+sys.path[0]+filename+' loaded!')\n",
    "\n",
    "#Extraction\n",
    "nsheets=book.nsheets\n",
    "\n",
    "sheet_names=book.sheet_names()\n",
    "sheets={}\n",
    "\n",
    "for sheet_name in sheet_names:    \n",
    "    nrows=book.sheet_by_name(sheet_name).nrows\n",
    "    current_header=book.sheet_by_name(sheet_name).row_values(2) \n",
    "    current_data=[book.sheet_by_name(sheet_name).row_values(i) for i in range(3, nrows)]\n",
    "    sheets[sheet_name]=pd.DataFrame(current_data, columns=current_header)   #DataFrame Construction\n",
    "#Feedback\n",
    "print('Data Extracted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dealing with the Missing Peak(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#///////////////////Main Loop///////////\n",
    "peak_missing_amount=0\n",
    "peak_redundant_amount=0\n",
    "peak_redundant_item=[]\n",
    "peak_missing_item=[]\n",
    "peak_repeated_amount=0\n",
    "peak_repeated_item=[]\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    df=sheets[sheet_name]\n",
    "\n",
    "    actual_rows=len(df.index)\n",
    "    mzs=list(df['m/z'])\n",
    "\n",
    "    #////////////////////Unique!!!!///////////////////////////////////////////////\n",
    "    for mz in mzs:\n",
    "        if len(df[df['m/z']==mz].index)>1:\n",
    "            del_index=list(df[df['m/z']==mz].index)\n",
    "            del_index.pop(0)\n",
    "            df=df.drop(del_index)\n",
    "\n",
    "            mzs=list(df['m/z'])\n",
    "\n",
    "            peak_repeated_amount+=1\n",
    "            peak_repeated_item.append(sheet_name.replace('_0_', ' @ ').replace('_1', ''))\n",
    "    #////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "    df=df.sort_index(by='m/z')\n",
    "    df=df.reset_index().drop('index', axis=1)\n",
    "\n",
    "    actual_rows=len(df.index)\n",
    "\n",
    "    #///////Larger than normal: Redundant///////////\n",
    "    if actual_rows>normal_rows:\n",
    "        mzs=list(df['m/z'])\n",
    "        mzs_adjacents=detect_redundant(mzs)    #Call Function          \n",
    "        df=pd.concat([df.ix[df[df['m/z']==mzs_adjacent].index] for mzs_adjacent in mzs_adjacents])        \n",
    "\n",
    "        #////Memorize the Redundant One//////////////////    \n",
    "        peak_redundant_amount+=1\n",
    "        peak_redundant_item.append(sheet_name.replace('_0_', ' @ ').replace('_1', ''))\n",
    "\n",
    "    #/////Sort & Reindex////////////\n",
    "    df=df.sort_index(by='m/z')\n",
    "    df=df.reset_index().drop('index', axis=1)\n",
    "\n",
    "    actual_rows=len(df.index)\n",
    "    \n",
    "    ##///////Less than normal: Missing///////\n",
    "    if actual_rows<normal_rows:\n",
    "        mzs=list(df['m/z'])\n",
    "        mzs_missing=detect_missed(mzs)  #Call Function \n",
    "\n",
    "        i=actual_rows\n",
    "        \n",
    "        for mz_missing in mzs_missing:\n",
    "            df.ix[i]=0\n",
    "            df['m/z'].ix[i]=mz_missing\n",
    "            i+=1\n",
    "\n",
    "        #////Memorize the Missing One///////\n",
    "        peak_missing_amount+=1\n",
    "        peak_missing_item.append(sheet_name.replace('_0_', ' @ ').replace('_1', ''))\n",
    "\n",
    "    df=df.sort_index(by='m/z')\n",
    "    df=df.reset_index().drop('index', axis=1)\n",
    "\n",
    "    actual_rows=len(df.index)    \n",
    "\n",
    "    #///////Again! Larger than normal: Redundant////////\n",
    "    if actual_rows>normal_rows:\n",
    "        mzs=list(df['m/z'])\n",
    "        mzs_adjacents=detect_redundant(mzs)     #Call Function          \n",
    "        df=pd.concat([df.ix[df[df['m/z']==mzs_adjacent].index] for mzs_adjacent in mzs_adjacents])       \n",
    "\n",
    "        #/Memorize the Redundant One\n",
    "        peak_redundant_amount+=1\n",
    "        peak_redundant_item.append(sheet_name.replace('_0_', ' @ ').replace('_1', ''))\n",
    "\n",
    "    #Sort & Reindex/////////////\n",
    "    df=df.sort_index(by='m/z')\n",
    "    df=df.reset_index().drop('index', axis=1)\n",
    "\n",
    "    #Descriptive Calculation\n",
    "    '''\n",
    "    hep_ratio=df['Area'].ix[2]/df['Area'].ix[3]\n",
    "    saa_ratio=df['Area'].ix[0]/df['Area'].ix[1]\n",
    "    '''\n",
    "\n",
    "    #Regular Expressions////Matching Sample Names\n",
    "    patt=r'[\\D\\d]+_0_'\n",
    "    name=re.findall(patt, sheet_name)[0].replace('_0_', '').replace('-', '_')\n",
    "\n",
    "    #Regular Expressions////Matching Vial NOs\n",
    "    patt1=r'_0_[\\D\\d]+_1$'\n",
    "    id=re.findall(patt1, sheet_name)[0].replace('_0_', '').replace('_1', '')\n",
    "\n",
    "    #Regular Expressions////Matching Tails of the Vials\n",
    "    patt2=r'\\d+$'\n",
    "    tail=int(re.findall(patt2, id)[0])\n",
    "\n",
    "    if len(id)==2:\n",
    "        id=id[0]+'0'+id[1]\n",
    "\n",
    "    df['Tail']=tail\n",
    "    df['id']=id\n",
    "    df['name']=name\n",
    "    #df['hep/hhep']=hep_ratio\n",
    "    #df['SAA/IS_SAA']=saa_ratio\n",
    "    df['tag']=name\n",
    "\n",
    "    sheets[sheet_name]=df\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Combination & Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining...\n",
      "Parsing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Combining DataFrame\n",
    "#Feedback: Combining\n",
    "print('Combining...')\n",
    "df=pd.concat([sheets[sheet_name] for sheet_name in sheet_names], keys=sheet_names)\n",
    "\n",
    "#Feedback: Start Parsing\n",
    "print('Parsing...')\n",
    "\n",
    "#去重\n",
    "names=list(df['name'].unique())\n",
    "\n",
    "#Description Statistics Initialization\n",
    "df['hep avg']=0\n",
    "df['hep std']=0\n",
    "df['hep CV']=0\n",
    "\n",
    "df['SAA avg']=0\n",
    "df['SAA std']=0\n",
    "df['SAA CV']=0\n",
    "\n",
    "#///Change the sheetnames from indeces into column names\n",
    "df=df.reset_index()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Descriptive Statistics for the same names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#////////Loop of Processing Data in the Same Names///////////////\n",
    "for name in names:\n",
    "    '''\n",
    "    avg=df['hep/hhep'][df['name']==name].mean()\n",
    "    df['hep avg'][df['name']==name]=avg\n",
    "\n",
    "    std=df['hep/hhep'][df['name']==name].std()\n",
    "    df['hep std'][df['name']==name]=std\n",
    "\n",
    "    cv=std*100/avg\n",
    "    df['hep CV'][df['name']==name]=cv\n",
    "\n",
    "    #////////////////////////////////////////////\n",
    "    \n",
    "    avg=df['SAA/IS_SAA'][df['name']==name].mean()\n",
    "    df['SAA avg'][df['name']==name]=avg\n",
    "\n",
    "    std=df['SAA/IS_SAA'][df['name']==name].std()\n",
    "    df['SAA std'][df['name']==name]=std\n",
    "\n",
    "    cv=std*100/avg\n",
    "    df['SAA CV'][df['name']==name]=cv\n",
    "    '''\n",
    "    #/////////////////////////////////////////////\n",
    "\n",
    "    if name.find('standard') != -1 or name.find('Standard') != -1:\n",
    "        tag=name.replace('standard', '').replace('Standard', '').replace('_', '').replace(' ', '')\n",
    "        df['tag'][df['name']==name]=tag     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Export the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming...\n",
      "Exporting...\n",
      "Files Exported!\n"
     ]
    }
   ],
   "source": [
    "#Calling Function\n",
    "print('Trimming...')\n",
    "#blank()\n",
    "\n",
    "#Sorting\n",
    "df=df.sort_index(by=['id', 'level_1'])\n",
    "df=df.set_index('level_0')\n",
    "\n",
    "#Output\n",
    "print('Exporting...')\n",
    "df.to_csv('.\\\\combined.csv')\n",
    "\n",
    "dfl=layout(sheet_names)\n",
    "dfl.to_csv('.\\\\layout.csv')\n",
    "print('Files Exported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>DM01</td>\n",
       "      <td>DM01</td>\n",
       "      <td>DM02</td>\n",
       "      <td>DM02</td>\n",
       "      <td>DM03</td>\n",
       "      <td>DM03</td>\n",
       "      <td>DM04</td>\n",
       "      <td>DM04</td>\n",
       "      <td>DM05</td>\n",
       "      <td>DM05</td>\n",
       "      <td>DM06</td>\n",
       "      <td>DM06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>DM07</td>\n",
       "      <td>DM07</td>\n",
       "      <td>DM08</td>\n",
       "      <td>DM08</td>\n",
       "      <td>DM09</td>\n",
       "      <td>DM09</td>\n",
       "      <td>DM10</td>\n",
       "      <td>DM10</td>\n",
       "      <td>DM11</td>\n",
       "      <td>DM11</td>\n",
       "      <td>DM12</td>\n",
       "      <td>DM12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>DM13</td>\n",
       "      <td>DM13</td>\n",
       "      <td>DM14</td>\n",
       "      <td>DM14</td>\n",
       "      <td>DM15</td>\n",
       "      <td>DM15</td>\n",
       "      <td>DM16</td>\n",
       "      <td>DM16</td>\n",
       "      <td>DM18</td>\n",
       "      <td>DM18</td>\n",
       "      <td>DM19</td>\n",
       "      <td>DM19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>DM20</td>\n",
       "      <td>DM20</td>\n",
       "      <td>DM21</td>\n",
       "      <td>DM21</td>\n",
       "      <td>DM22</td>\n",
       "      <td>DM22</td>\n",
       "      <td>DM23</td>\n",
       "      <td>DM23</td>\n",
       "      <td>DM24</td>\n",
       "      <td>DM24</td>\n",
       "      <td>DM25</td>\n",
       "      <td>DM25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>DM26</td>\n",
       "      <td>DM26</td>\n",
       "      <td>DM27</td>\n",
       "      <td>DM27</td>\n",
       "      <td>DM28</td>\n",
       "      <td>DM28</td>\n",
       "      <td>DM29</td>\n",
       "      <td>DM29</td>\n",
       "      <td>DM30</td>\n",
       "      <td>DM30</td>\n",
       "      <td>STD_0</td>\n",
       "      <td>STD_1.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>STD_3.125</td>\n",
       "      <td>STD_6.25</td>\n",
       "      <td>STD_12.5</td>\n",
       "      <td>STD_25</td>\n",
       "      <td>STD_50</td>\n",
       "      <td>STD_100</td>\n",
       "      <td>STD_0</td>\n",
       "      <td>STD_1.5625</td>\n",
       "      <td>STD_3.125</td>\n",
       "      <td>STD_6.25</td>\n",
       "      <td>STD_12.5</td>\n",
       "      <td>STD_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>STD_50</td>\n",
       "      <td>STD_100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3       4       5        6      7           8   \\\n",
       "A       DM01      DM01      DM02    DM02    DM03     DM03   DM04        DM04   \n",
       "B       DM07      DM07      DM08    DM08    DM09     DM09   DM10        DM10   \n",
       "C       DM13      DM13      DM14    DM14    DM15     DM15   DM16        DM16   \n",
       "D       DM20      DM20      DM21    DM21    DM22     DM22   DM23        DM23   \n",
       "E       DM26      DM26      DM27    DM27    DM28     DM28   DM29        DM29   \n",
       "F  STD_3.125  STD_6.25  STD_12.5  STD_25  STD_50  STD_100  STD_0  STD_1.5625   \n",
       "G     STD_50   STD_100       NaN     NaN     NaN      NaN    NaN         NaN   \n",
       "H        NaN       NaN       NaN     NaN     NaN      NaN    NaN         NaN   \n",
       "\n",
       "          9         10        11          12  \n",
       "A       DM05      DM05      DM06        DM06  \n",
       "B       DM11      DM11      DM12        DM12  \n",
       "C       DM18      DM18      DM19        DM19  \n",
       "D       DM24      DM24      DM25        DM25  \n",
       "E       DM30      DM30     STD_0  STD_1.5625  \n",
       "F  STD_3.125  STD_6.25  STD_12.5      STD_25  \n",
       "G        NaN       NaN       NaN         NaN  \n",
       "H        NaN       NaN       NaN         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n",
      "\n",
      "Total Sample Amount:  74\n",
      "\tPeak Missing:  35\n",
      "\t\tMissing Item(s):  ['DM01 @ A1', 'DM01 @ A2', 'DM09 @ B5', 'DM09 @ B6', 'DM10 @ B7', 'DM11 @ B10', 'DM11 @ B9', 'DM12 @ B11', 'DM12 @ B12', 'DM13 @ C1', 'DM13 @ C2', 'DM14 @ C3', 'DM14 @ C4', 'DM16 @ C10', 'DM16 @ C8', 'DM18 @ C11', 'DM18 @ C12', 'DM19 @ D1', 'DM19 @ D2', 'DM20 @ D3', 'DM20 @ D4', 'DM21 @ D5', 'DM21 @ D6', 'DM23 @ D10', 'DM23 @ D9', 'DM24 @ D11', 'DM24 @ D12', 'DM26 @ E3', 'DM26 @ E4', 'DM27 @ E5', 'DM27 @ E6', 'DM28 @ E8', 'DM29 @ E9', 'DM30 @ E11', 'DM30 @ E12'] \n",
      "\n",
      "\tPeak Redundant:  2\n",
      "\t\tRedundant Item(s):  ['DM06 @ A12', 'DM07 @ B2'] \n",
      "\n",
      "\tPeak Repeated:  0\n",
      "\t\tRepeated Item(s):  [] \n",
      "\n",
      "Combined Document Exported:  \\combined.csv\n",
      "Layout Document Exported:  \\layout.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final Feedback\n",
    "print('\\nDone!\\n')\n",
    "\n",
    "print('Total Sample Amount: ', nsheets)\n",
    "\n",
    "print('\\tPeak Missing: ', peak_missing_amount)\n",
    "print('\\t\\tMissing Item(s): ', peak_missing_item, '\\n')\n",
    "\n",
    "print('\\tPeak Redundant: ', peak_redundant_amount)\n",
    "print('\\t\\tRedundant Item(s): ', peak_redundant_item, '\\n')\n",
    "\n",
    "print('\\tPeak Repeated: ', peak_repeated_amount)\n",
    "print('\\t\\tRepeated Item(s): ', peak_repeated_item, '\\n')\n",
    "\n",
    "print('Combined Document Exported: ', sys.path[0]+'\\\\combined.csv')\n",
    "print('Layout Document Exported: ', sys.path[0]+'\\\\layout.csv\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
